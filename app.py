
# pip install flask flask-cors google-generativeai supabase python-dotenv werkzeug

import os
import sys
import json
import tempfile
import mimetypes
import re
from typing import List, Dict, Any, Tuple, Optional

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename

import google.generativeai as genai
from supabase import create_client, Client

# Ensure UTF-8 output
sys.stdout.reconfigure(encoding='utf-8')

# -----------------------------
# Config via environment vars
# -----------------------------
GEMINI_API_KEY = "AIzaSyAl3Kc7fo8_T9rAMhEqocw5d7gchtLL1Wg"
SUPABASE_URL ="https://acddbjalchiruigappqg.supabase.co"
SUPABASE_ANON_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImFjZGRiamFsY2hpcnVpZ2FwcHFnIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTkwMzAzMTQsImV4cCI6MjA3NDYwNjMxNH0.Psefs-9-zIwe8OjhjQOpA19MddU3T9YMcfFtMcYQQS4"

if not GEMINI_API_KEY or not SUPABASE_URL or not SUPABASE_ANON_KEY:
    print("Please set GEMINI_API_KEY, SUPABASE_URL, SUPABASE_ANON_KEY in environment.")
    sys.exit(1)

genai.configure(api_key=GEMINI_API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)

model = genai.GenerativeModel("gemini-2.0-flash")

app = Flask(__name__)
CORS(app)

MAX_FILE_SIZE = 20 * 1024 * 1024  # 20MB
ALLOWED_IMAGE_EXT = {"jpg", "jpeg", "png", "webp"}


def is_allowed_image(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_IMAGE_EXT


def get_mime_type(filename: str) -> str:
    mtype, _ = mimetypes.guess_type(filename)
    return mtype or "application/octet-stream"


# ===================================
# IMPROVED EXTRACTION PROMPT - WITH SMART PRICE ANALYSIS
# ===================================
EXTRACTION_PROMPT = """B·∫°n l√† tr·ª£ l√Ω th√¥ng minh ph√¢n t√≠ch y√™u c·∫ßu mua s·∫Øm th·ªùi trang.

NHI·ªÜM V·ª§: Ph√¢n t√≠ch tin nh·∫Øn ƒë·ªÉ x√°c ƒë·ªãnh √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng V√Ä PH√ÇN T√çCH GI√Å CH√çNH X√ÅC.

PH√ÇN LO·∫†I √ù ƒê·ªäNH:
1. "greeting" - Ch√†o h·ªèi: "xin ch√†o", "hi", "hello", "ch√†o shop"
2. "general_question" - H·ªèi chung: "shop ·ªü ƒë√¢u", "giao h√†ng th·∫ø n√†o", "c√≥ uy t√≠n kh√¥ng"
3. "style_advice" - Xin t∆∞ v·∫•n: "m·∫∑c g√¨ ƒë·∫πp", "ph·ªëi ƒë·ªì th·∫ø n√†o", "h·ª£p v·ªõi t√¥i kh√¥ng"
4. "product_search" - T√¨m s·∫£n ph·∫©m: "t√¨m v√°y", "c√≥ √°o s∆° mi kh√¥ng", "xem qu·∫ßn jean"
5. "product_question" - H·ªèi v·ªÅ s·∫£n ph·∫©m c·ª• th·ªÉ: "size n√†o", "c√≤n m√†u ƒëen kh√¥ng", "gi√° bao nhi√™u"

‚ö†Ô∏è PH√ÇN T√çCH GI√Å TH√îNG MINH (QUAN TR·ªåNG):
Khi ng∆∞·ªùi d√πng n√≥i v·ªÅ gi√°, h√£y PH√ÇN T√çCH CH√çNH X√ÅC:

1. **GI√Å T·ªêI ƒêA (max only):**
   - "300k tr·ªü xu·ªëng" ‚Üí min: null, max: 300000
   - "d∆∞·ªõi 500k" ‚Üí min: null, max: 500000
   - "kh√¥ng qu√° 400k" ‚Üí min: null, max: 400000
   - "t·ªëi ƒëa 300k" ‚Üí min: null, max: 300000

2. **GI√Å T·ªêI THI·ªÇU (min only):**
   - "500k tr·ªü l√™n" ‚Üí min: 500000, max: null
   - "tr√™n 300k" ‚Üí min: 300000, max: null
   - "√≠t nh·∫•t 400k" ‚Üí min: 400000, max: null

3. **KHO·∫¢NG GI√Å (range):**
   - "300k-500k" ‚Üí min: 300000, max: 500000
   - "t·ª´ 200k ƒë·∫øn 400k" ‚Üí min: 200000, max: 400000

4. **GI√Å KHO·∫¢NG (around ¬±20%):**
   - "t·∫ßm 300k" ‚Üí min: 240000, max: 360000
   - "kho·∫£ng 500k" ‚Üí min: 400000, max: 600000

5. **ƒê∆†N V·ªä:**
   - "300" ho·∫∑c "300k" ‚Üí 300,000 VNƒê
   - "1tr" ho·∫∑c "1 tri·ªáu" ‚Üí 1,000,000 VNƒê

CH·ªà TR√çCH XU·∫§T th√¥ng tin s·∫£n ph·∫©m KHI user_intent l√† "product_search" ho·∫∑c "product_question".

TR·∫¢ V·ªÄ JSON:
{
  "user_intent": "greeting | general_question | style_advice | product_search | product_question",
  "confidence": 0.0-1.0,
  "should_search_products": true/false,
  "type": "v√°y | √°o | qu·∫ßn | ch√¢n v√°y | √°o s∆° mi | √°o thun | qu·∫ßn jean | ƒë·∫ßm | ...",
  "colors": ["ƒëen", "tr·∫Øng", "xanh navy", ...],
  "material": "cotton | jeans | l·ª•a | len | da | ...",
  "pattern": "tr∆°n | k·∫ª s·ªçc | caro | hoa | ch·∫•m bi | ...",
  "style": ["c√¥ng s·ªü", "d·∫°o ph·ªë", "d·ª± ti·ªác", "th·ªÉ thao", ...],
  "length": "ng·∫Øn | midi | d√†i | qua g·ªëi | ...",
  "sleeve": "s√°t n√°ch | ng·∫Øn tay | d√†i tay | ...",
  "fit": "√¥m | su√¥ng | r·ªông | ...",
  "price_range": {"min": 200000, "max": 500000},
  "price_analysis": "Gi·∫£i th√≠ch c√°ch b·∫°n ph√¢n t√≠ch gi√°",
  "keywords": ["t·ª´ kh√≥a t√¨m ki·∫øm"],
  "conversation_context": "ph√¢n t√≠ch ng·∫Øn v·ªÅ ng·ªØ c·∫£nh"
}

QUY T·∫ÆC QUAN TR·ªåNG:
- should_search_products = true CH·ªà KHI c√≥ √Ω ƒë·ªãnh t√¨m/mua s·∫£n ph·∫©m r√µ r√†ng
- keywords PH·∫¢I r·ªóng [] n·∫øu kh√¥ng c√≥ √Ω ƒë·ªãnh t√¨m s·∫£n ph·∫©m
- keywords KH√îNG BAO GI·ªú ch·ª©a "kh√¥ng r√µ" ho·∫∑c gi√° tr·ªã m∆° h·ªì
- price_range PH·∫¢I ch√≠nh x√°c d·ª±a tr√™n √Ω ƒë·ªãnh ng∆∞·ªùi d√πng
- N·∫øu ch·ªâ ch√†o h·ªèi: user_intent="greeting", should_search_products=false, keywords=[]
- N·∫øu h·ªèi t∆∞ v·∫•n chung: user_intent="style_advice", should_search_products=false

V√ç D·ª§:
Input: "xin ch√†o"
Output: {"user_intent": "greeting", "should_search_products": false, "keywords": []}

Input: "t√¨m v√°y ƒëen gi√° 300k tr·ªü xu·ªëng"
Output: {"user_intent": "product_search", "should_search_products": true, "type": "v√°y", "colors": ["ƒëen"], "price_range": {"min": null, "max": 300000}, "price_analysis": "300k tr·ªü xu·ªëng = t·ªëi ƒëa 300k", "keywords": ["v√°y ƒëen"]}

Input: "v√°y t·∫ßm 300k"
Output: {"user_intent": "product_search", "should_search_products": true, "type": "v√°y", "price_range": {"min": 240000, "max": 360000}, "price_analysis": "t·∫ßm 300k = kho·∫£ng ¬±20%", "keywords": ["v√°y"]}

Input: "m·∫∑c g√¨ ƒë·∫πp?"
Output: {"user_intent": "style_advice", "should_search_products": false, "keywords": []}
"""


# ===================================
# IMPROVED CHAT PROMPT
# ===================================
CHAT_PROMPT = """B·∫°n l√† Mina - tr·ª£ l√Ω th·ªùi trang th√¢n thi·ªán, nhi·ªát t√¨nh c·ªßa Zamy Shop. 

üéØ T√çNH C√ÅCH C·ª¶A B·∫†N:
- Th√¢n thi·ªán, g·∫ßn g≈©i nh∆∞ ng∆∞·ªùi b·∫°n (kh√¥ng kh√°ch s√°o)
- Nhi·ªát t√¨nh nh∆∞ng kh√¥ng √°p ƒë·∫∑t
- Tinh t·∫ø, hi·ªÉu t√¢m l√Ω ph·ª• n·ªØ
- S·ª≠ d·ª•ng emoji t·ª± nhi√™n (1-2/c√¢u): üòä üíï ‚ú® üëó 
- ƒê·∫∑t c√¢u h·ªèi m·ªü ƒë·ªÉ hi·ªÉu r√µ kh√°ch h√†ng
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch (2-4 c√¢u)

üë§ TH√îNG TIN KH√ÅCH H√ÄNG:
- T√™n: {customer_name}
- Chi·ªÅu cao: {height} | C√¢n n·∫∑ng: {weight}  
- M√†u y√™u th√≠ch: {favorite_colors}

üìù L·ªäCH S·ª¨ TR√í CHUY·ªÜN:
{chat_history}

üé® √ù ƒê·ªäNH HI·ªÜN T·∫†I: {current_intent}
üì¶ S·∫¢N PH·∫®M T√åM ƒê∆Ø·ª¢C: {products_found}

---

H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI THEO T·ª™NG T√åNH HU·ªêNG:

1Ô∏è‚É£ CH√ÄO H·ªéI L·∫¶N ƒê·∫¶U (user_intent = "greeting"):
‚úÖ L√†m:
- Ch√†o th√¢n m·∫≠t, ·∫•m √°p
- Gi·ªõi thi·ªáu ng·∫Øn g·ªçn v·ªÅ m√¨nh
- H·ªèi t√™n kh√°ch (n·∫øu ch∆∞a bi·∫øt)
- H·ªèi m·ªü: "H√¥m nay b·∫°n c·∫ßn t√¨m g√¨?" ho·∫∑c "M√¨nh c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"

‚ùå Kh√¥ng l√†m:
- Kh√¥ng li·ªát k√™ s·∫£n ph·∫©m ngay
- Kh√¥ng h·ªèi qu√° nhi·ªÅu c√¢u c√πng l√∫c
- Kh√¥ng d√πng ng√¥n ng·ªØ marketing

V√≠ d·ª• t·ªët:
"Ch√†o b·∫°n! M√¨nh l√† Mina, tr·ª£ l√Ω th·ªùi trang c·ªßa Zamy Shop ƒë√¢y üòä R·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n h√¥m nay! B·∫°n t√™n g√¨ nh·ªâ?"

2Ô∏è‚É£ T∆Ø V·∫§N PHONG C√ÅCH (user_intent = "style_advice"):
‚úÖ L√†m:
- ƒê·∫∑t c√¢u h·ªèi ƒë·ªÉ hi·ªÉu r√µ: d·ªãp g√¨? phong c√°ch n√†o?
- Ph√¢n t√≠ch d·ª±a tr√™n chi·ªÅu cao/c√¢n n·∫∑ng
- G·ª£i √Ω 2-3 style c·ª• th·ªÉ v·ªõi L√ù DO
- K·∫øt th√∫c b·∫±ng c√¢u h·ªèi ti·∫øp theo

V√≠ d·ª• t·ªët:
"V·ªõi chi·ªÅu cao {height} v√† v√≥c d√°ng c√¢n ƒë·ªëi c·ªßa b·∫°n, m√¨nh nghƒ© b·∫°n s·∫Ω r·∫•t h·ª£p v·ªõi:
- V√°y ch·ªØ A midi: t√¥n d√°ng v√† thanh l·ªãch 
- Qu·∫ßn ·ªëng su√¥ng + √°o croptop: tr·∫ª trung, nƒÉng ƒë·ªông

B·∫°n ƒë·ªãnh m·∫∑c ƒëi ƒë√¢u nh·ªâ? C√¥ng s·ªü hay ƒëi ch∆°i?"

3Ô∏è‚É£ T√åM S·∫¢N PH·∫®M - C√ì K·∫æT QU·∫¢ (products_found > 0):
‚úÖ L√†m:
- X√°c nh·∫≠n ƒë√£ hi·ªÉu nhu c·∫ßu
- Th√¥ng b√°o t√¨m ƒë∆∞·ª£c s·∫£n ph·∫©m m·ªôt c√°ch t·ª± nhi√™n
- Nh·∫•n m·∫°nh ∆∞u ƒëi·ªÉm n·ªïi b·∫≠t (1-2 ƒëi·ªÉm)
- H·ªèi xem c√≥ c·∫ßn filter th√™m kh√¥ng

‚ùå Kh√¥ng l√†m:
- Kh√¥ng n√≥i "Tuy·ªát v·ªùi! T√¥i ƒë√£ t√¨m th·∫•y..."
- Kh√¥ng d√πng c√¢u template c·ª©ng nh·∫Øc

V√≠ d·ª• t·ªët:
"M√¨nh t√¨m ƒë∆∞·ª£c m·∫•y em v√°y ƒë·∫πp trong t·∫ßm gi√° b·∫°n c·∫ßn lu√¥n! üòç C√≥ c·∫£ m√†u ƒëen v√† tr·∫Øng, v·ª´a t√∫i ti·ªÅn m√† ch·∫•t l∆∞·ª£ng t·ªët n√®.

B·∫°n th√≠ch d√°ng n√†o h∆°n: √¥m hay su√¥ng?"

4Ô∏è‚É£ T√åM S·∫¢N PH·∫®M - KH√îNG C√ì K·∫æT QU·∫¢ (products_found = 0):
‚ùå TUY·ªÜT ƒê·ªêI KH√îNG ƒê∆Ø·ª¢C:
- H·ªèi th√™m th√¥ng tin ho·∫∑c y√™u c·∫ßu l√†m r√µ
- N√≥i "hi·ªán t·∫°i kh√¥ng c√≥" r·ªìi d·ª´ng l·∫°i
- Ch·ªâ xin l·ªói m√† kh√¥ng ƒë∆∞a ra gi·∫£i ph√°p

‚úÖ B·∫ÆT BU·ªòC PH·∫¢I L√ÄM:
- Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao kh√¥ng t√¨m th·∫•y (h·∫øt h√†ng, gi√° kh√¥ng ph√π h·ª£p...)
- NGAY L·∫¨P T·ª®C ƒë·ªÅ xu·∫•t 2-3 s·∫£n ph·∫©m thay th·∫ø c·ª• th·ªÉ
- Nh·∫•n m·∫°nh ∆∞u ƒëi·ªÉm c·ªßa s·∫£n ph·∫©m thay th·∫ø
- H·ªèi xem kh√°ch c√≥ mu·ªën xem kh√¥ng (c√¢u ƒë√≥ng, d·ªÖ tr·∫£ l·ªùi)

V√≠ d·ª• t·ªët:
"V√°y ƒëen √¥m body gi√° d∆∞·ªõi 300k hi·ªán t·∫°i ƒëang h·∫øt h√†ng r·ªìi b·∫°n ∆°i üò¢ 

Nh∆∞ng m√¨nh c√≥ m·∫•y l·ª±a ch·ªçn t∆∞∆°ng t·ª± c≈©ng ƒë·∫πp l·∫Øm n√®:
- V√°y xanh navy √¥m d√°ng: thanh l·ªãch, gi√° 280k
- V√°y ƒëen su√¥ng: d·ªÖ m·∫∑c h∆°n, 250k

B·∫°n mu·ªën xem kh√¥ng? üòä"

5Ô∏è‚É£ TR·∫¢ L·ªúI C√ÇU H·ªéI CHUNG (user_intent = "general_question"):
‚úÖ L√†m:
- Tr·∫£ l·ªùi tr·ª±c ti·∫øp, ng·∫Øn g·ªçn
- Th√™m th√¥ng tin h·ªØu √≠ch li√™n quan
- H·ªèi li·ªáu c√≤n th·∫Øc m·∫Øc g√¨ kh√¥ng

V√≠ d·ª• t·ªët:
"Zamy Shop giao h√†ng to√†n qu·ªëc trong 2-3 ng√†y b·∫°n nh√©! Freeship cho ƒë∆°n t·ª´ 300k üöö

B·∫°n ·ªü t·ªânh n√†o? M√¨nh check gi√∫p th·ªùi gian giao c·ª• th·ªÉ nha!"

---

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- LU√îN g·ªçi kh√°ch h√†ng l√† "b·∫°n" (kh√¥ng d√πng "ch·ªã", "c√¥", "anh")
- S·ª¨ D·ª§NG ng√¥i "m√¨nh" thay v√¨ "t√¥i" ho·∫∑c "em"
- TR√ÅNH c√°c c·ª•m t·ª´ AI: "T√¥i c√≥ th·ªÉ gi√∫p", "T√¥i l√† tr·ª£ l√Ω AI"
- M·ªñI c√¢u tr·∫£ l·ªùi N√äN c√≥ 1 c√¢u h·ªèi m·ªü ·ªü cu·ªëi
- ƒê·ªåC k·ªπ l·ªãch s·ª≠ chat, KH√îNG l·∫∑p l·∫°i c√¢u h·ªèi ƒë√£ h·ªèi
- N·∫æU kh√°ch ƒë√£ cung c·∫•p th√¥ng tin, H√ÉY s·ª≠ d·ª•ng ngay (t√™n, s·ªü th√≠ch...)
- KH√îNG ƒë·ªÅ c·∫≠p "s·∫£n ph·∫©m trong database" - n√≥i t·ª± nhi√™n
- CH·ªà g·ª£i √Ω s·∫£n ph·∫©m C√ì TH·∫¨T, kh√¥ng b·ªãa ra
- üö® TUY·ªÜT ƒê·ªêI KH√îNG B·ªäA GI√Å - Ch·ªâ d√πng gi√° t·ª´ danh s√°ch s·∫£n ph·∫©m ƒë∆∞·ª£c cung c·∫•p
- üö® KHI n√≥i v·ªÅ gi√°, PH·∫¢I d√πng CH√çNH X√ÅC s·ªë ti·ªÅn t·ª´ th√¥ng tin s·∫£n ph·∫©m, KH√îNG l√†m tr√≤n

---

H√ÉY TR·∫¢ L·ªúI TIN NH·∫ÆN SAU ƒê√ÇY:
User: {user_message}
"""


def extract_keywords_with_gemini(user_message: str, file_path: str | None, mime_type: str | None) -> Dict[str, Any]:
    """Extract keywords and intent from user message with SMART PRICE DETECTION"""
    try:
        if file_path:
            uploaded_file = genai.upload_file(file_path, mime_type=mime_type)
            parts = [uploaded_file, user_message or "H√£y ph√¢n t√≠ch ·∫£nh n√†y."]
        else:
            parts = [user_message or ""]

        response = model.generate_content([EXTRACTION_PROMPT, *parts])
        text = (response.text or "").strip()
        
        # Remove markdown code blocks if present
        if text.startswith("```"):
            lines = text.split("\n")
            text = "\n".join(lines[1:-1]) if len(lines) > 2 else text
        text = text.strip()

        def try_parse_json(s: str):
            try:
                return json.loads(s)
            except Exception:
                start = s.find("{")
                end = s.rfind("}")
                if start != -1 and end != -1 and end > start:
                    return json.loads(s[start:end + 1])
                raise

        data = try_parse_json(text)
        
        # Ensure keywords is a list and doesn't contain "kh√¥ng r√µ"
        keywords = data.get("keywords", [])
        if not isinstance(keywords, list):
            keywords = []
        keywords = [k for k in keywords if k and isinstance(k, str) and k.strip() and "kh√¥ng r√µ" not in k.lower()]
        
        # Build keywords from structured data if empty
        if not keywords and data.get("should_search_products", False):
            type_ = data.get("type") or ""
            colors = data.get("colors") or []
            material = data.get("material") or ""
            pattern = data.get("pattern") or ""
            style = data.get("style") or []
            
            candidates = []
            base = type_.strip()
            if base:
                candidates.append(base)
                if colors:
                    for c in colors[:2]:
                        candidates.append(f"{base} {c}")
                if pattern and pattern != "kh√¥ng r√µ":
                    candidates.append(f"{base} {pattern}")
                if material and material != "kh√¥ng r√µ":
                    candidates.append(f"{base} {material}")
            
            keywords = candidates[:6]
        
        # Remove duplicates while preserving order
        keywords = list(dict.fromkeys([k.strip() for k in keywords if k.strip()]))[:8]
        
        # Extract price range from AI analysis
        price_range = data.get("price_range", {})
        min_price = price_range.get("min") if isinstance(price_range, dict) else None
        max_price = price_range.get("max") if isinstance(price_range, dict) else None
        price_analysis = data.get("price_analysis", "")
        
        out = {
            "keywords": keywords,
            "user_intent": data.get("user_intent", "general_question"),
            "should_search_products": data.get("should_search_products", False),
            "confidence": data.get("confidence", 0.5),
            "conversation_context": data.get("conversation_context", ""),
            "price_min": min_price,
            "price_max": max_price,
            "price_analysis": price_analysis,
        }
        
        # Copy other fields
        for k in ["type","colors","material","pattern","style","length","sleeve","fit"]:
            if k in data:
                out[k] = data[k]
        
        print(f"üîç [EXTRACTION] Intent: {out['user_intent']}, Should search: {out['should_search_products']}, Keywords: {keywords}")
        print(f"üí∞ [PRICE AI] Min: {min_price}, Max: {max_price} - {price_analysis}")
        
        return out
        
    except Exception as e:
        print(f"[extract_keywords_with_gemini] error: {e}")
        # Safe fallback
        return {
            "keywords": [],
            "user_intent": "general_question",
            "should_search_products": False,
            "confidence": 0.0,
            "conversation_context": "L·ªói ph√¢n t√≠ch",
            "price_min": None,
            "price_max": None,
            "price_analysis": ""
        }


def build_or_clause_for_keywords(columns: List[str], keywords: List[str]) -> str:
    parts = []
    for kw in keywords:
        pattern = f"%{kw}%"
        for col in columns:
            parts.append(f"{col}.ilike.{pattern}")
    return ",".join(parts)


def score_product(product: Dict[str, Any], keywords: List[str]) -> int:
    text = f"{product.get('ten_san_pham','')} {product.get('mo_ta_san_pham','')}".lower()
    cnt = 0
    for kw in keywords:
        if kw.lower() in text:
            cnt += 1
    return cnt


def map_product_row(row: Dict[str, Any]) -> Dict[str, Any]:
    images = []
    if isinstance(row.get("product_images"), list):
        for img in row["product_images"]:
            url = img.get("duong_dan_anh")
            if isinstance(url, str):
                images.append(url)

    return {
        "id": int(row.get("ma_san_pham")) if row.get("ma_san_pham") else None,
        "name": row.get("ten_san_pham"),
        "description": row.get("mo_ta_san_pham"),
        "price": float(row.get("gia_ban") or 0.0),
        "original_price": float(row.get("muc_gia_goc") or 0.0),
        "images": images,
    }


@app.route("/api/search_products", methods=["POST"])
def search_products():
    try:
        user_message = ""
        file_path = None
        mime_type = None

        if request.content_type and "multipart/form-data" in request.content_type:
            user_message = request.form.get("message", "") or ""
            file = request.files.get("file")
            if file and file.filename:
                if not is_allowed_image(file.filename):
                    return jsonify({"error": "Ch·ªâ ch·∫•p nh·∫≠n ·∫£nh .jpg, .jpeg, .png, .webp"}), 400
                file.seek(0, os.SEEK_END)
                size = file.tell()
                file.seek(0)
                if size > MAX_FILE_SIZE:
                    return jsonify({"error": "File qu√° l·ªõn (t·ªëi ƒëa 20MB)"}), 400

                filename = secure_filename(file.filename)
                mime_type = get_mime_type(filename)
                suffix = "." + filename.rsplit(".", 1)[1].lower()
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                    file.save(tmp.name)
                    file_path = tmp.name
        else:
            data = request.get_json(silent=True) or {}
            user_message = data.get("message", "") or ""

        extracted = extract_keywords_with_gemini(user_message, file_path, mime_type)
        keywords: List[str] = extracted.get("keywords", [])[:6]
        
        # Clean up temp file
        if file_path and os.path.exists(file_path):
            try:
                os.unlink(file_path)
            except Exception:
                pass

        # If no product search intent, return empty
        if not extracted.get("should_search_products", False) or not keywords:
            return jsonify({
                "keywords": keywords,
                "products": [],
                "user_intent": extracted.get("user_intent"),
                "notes": extracted.get("conversation_context", "")
            })

        # Get price from AI analysis
        min_price = extracted.get("price_min")
        max_price = extracted.get("price_max")
        det_type = (extracted.get("type") or "").strip().lower() or None
        det_colors = [c.strip().lower() for c in (extracted.get("colors") or []) if isinstance(c, str) and c.strip()]

        # Build search query
        columns = ["ten_san_pham", "mo_ta_san_pham"]
        or_clause = build_or_clause_for_keywords(columns, keywords)
        
        q = supabase.table("products").select(
            "ma_san_pham,ten_san_pham,mo_ta_san_pham,gia_ban,muc_gia_goc,product_images(duong_dan_anh)"
        )
        
        # Apply filters
        if min_price is not None:
            q = q.gte("gia_ban", min_price)
            print(f"üí∞ [FILTER] Min price: {min_price}")
        if max_price is not None:
            q = q.lte("gia_ban", max_price)
            print(f"üí∞ [FILTER] Max price: {max_price}")
        if det_type:
            type_clause = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], [det_type])
            if type_clause:
                q = q.or_(type_clause)
        if det_colors:
            color_clause = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], det_colors[:2])
            if color_clause:
                q = q.or_(color_clause)
        if or_clause:
            q = q.or_(or_clause)
        
        resp = q.limit(20).execute()
        rows = resp.data or []

        # Fallback search if no results
        if not rows and keywords:
            single_tokens = [t for t in keywords if len(t.split()) == 1]
            if single_tokens:
                or_clause_2 = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], single_tokens)
                q2 = supabase.table("products").select(
                    "ma_san_pham,ten_san_pham,mo_ta_san_pham,gia_ban,muc_gia_goc,product_images(duong_dan_anh)"
                )
                if min_price is not None:
                    q2 = q2.gte("gia_ban", min_price)
                if max_price is not None:
                    q2 = q2.lte("gia_ban", max_price)
                if or_clause_2:
                    q2 = q2.or_(or_clause_2)
                resp2 = q2.limit(20).execute()
                rows = resp2.data or []
        
        # Sort by relevance
        def rank_row(r: Dict[str, Any]) -> tuple:
            name = (r.get("ten_san_pham") or "").lower()
            desc = (r.get("mo_ta_san_pham") or "").lower()
            txt = name + " " + desc
            score = score_product(r, keywords)
            type_bonus = 3 if det_type and det_type in txt else 0
            color_bonus = 0
            if det_colors:
                color_bonus = sum(1 for c in det_colors if c in txt)
            price_penalty = 0
            price = float(r.get("gia_ban") or 0)
            if min_price is not None or max_price is not None:
                center = ((min_price or price) + (max_price or price)) / 2.0
                price_penalty = abs(price - center) / max(center, 1.0)
            return (score + type_bonus + color_bonus, -price_penalty)

        rows_sorted = sorted(rows, key=lambda r: rank_row(r), reverse=True)
        products = [map_product_row(r) for r in rows_sorted]

        return jsonify({
            "keywords": keywords,
            "user_intent": extracted.get("user_intent"),
            "notes": extracted.get("conversation_context", ""),
            "price_analysis": extracted.get("price_analysis", ""),
            "count": len(products),
            "products": products
        })

    except Exception as e:
        print(f"‚ùå Error /api/search_products: {e}")
        return jsonify({"error": f"L·ªói m√°y ch·ªß: {str(e)}"}), 500


def generate_ai_response(
    user_message: str,
    chat_history: List[Dict],
    user_profile: Dict,
    file_path: str | None = None,
    mime_type: str | None = None,
) -> Dict[str, Any]:
    """Generate AI response for chat with improved natural conversation and ALWAYS show products"""
    try:
        # Extract user info with safe defaults
        customer_name = user_profile.get('name', 'b·∫°n') if user_profile else 'b·∫°n'
        height = user_profile.get('height', 'ch∆∞a r√µ') if user_profile else 'ch∆∞a r√µ'
        weight = user_profile.get('weight', 'ch∆∞a r√µ') if user_profile else 'ch∆∞a r√µ'
        favorite_colors = user_profile.get('favorite_colors', []) if user_profile else []
        
        if isinstance(favorite_colors, list):
            favorite_colors_str = ', '.join(favorite_colors) if favorite_colors else 'ch∆∞a r√µ'
        else:
            favorite_colors_str = str(favorite_colors) if favorite_colors else 'ch∆∞a r√µ'
        
        # Build chat history context (last 5 messages)
        chat_context = []
        if chat_history and isinstance(chat_history, list):
            for msg in chat_history[-5:]:
                try:
                    if not isinstance(msg, dict):
                        continue
                    
                    msg_type = msg.get('type', '') or msg.get('role', '') or msg.get('sender', '')
                    message = msg.get('message', '') or msg.get('content', '') or msg.get('text', '')
                    
                    if msg_type.lower() in ('user', 'human', 'customer'):
                        role = "Kh√°ch h√†ng"
                    elif msg_type.lower() in ('ai', 'assistant', 'bot', 'mina'):
                        role = "Mina"
                    else:
                        role = "Kh√°ch h√†ng"
                    
                    if message and isinstance(message, str) and message.strip():
                        chat_context.append(f"{role}: {message.strip()}")
                except Exception as msg_error:
                    print(f"‚ö†Ô∏è [Chat History] Error processing message: {msg_error}")
                    continue
        
        chat_history_str = '\n'.join(chat_context) if chat_context else "Ch∆∞a c√≥ l·ªãch s·ª≠"
        
        # Extract keywords and intent first
        extracted = extract_keywords_with_gemini(user_message, file_path, mime_type)
        keywords = extracted.get("keywords", [])[:6]
        user_intent = extracted.get("user_intent", "general_question")
        should_search = extracted.get("should_search_products", False)
        
        print(f"ü§ñ [AI] Intent: {user_intent}, Should search: {should_search}")
        
        # Search for products if needed
        suggested_products = []
        search_fallback_level = 0
        
        if should_search and keywords:
            print(f"üîç [SEARCH] Keywords: {keywords}")
            
            # Get price from AI analysis
            min_price = extracted.get("price_min")
            max_price = extracted.get("price_max")
            det_type = (extracted.get("type") or "").strip().lower()
            det_colors = [c.strip().lower() for c in (extracted.get("colors") or []) if isinstance(c, str) and c.strip()]
            
            # Build query
            columns = ["ten_san_pham", "mo_ta_san_pham"]
            or_clause = build_or_clause_for_keywords(columns, keywords)
            
            q = supabase.table("products").select(
                "ma_san_pham,ten_san_pham,mo_ta_san_pham,gia_ban,muc_gia_goc,product_images(duong_dan_anh)"
            )
            
            if min_price is not None:
                q = q.gte("gia_ban", min_price)
                print(f"üí∞ [FILTER] Min price: {min_price}")
            if max_price is not None:
                q = q.lte("gia_ban", max_price)
                print(f"üí∞ [FILTER] Max price: {max_price}")
            if det_type:
                type_clause = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], [det_type])
                if type_clause:
                    q = q.or_(type_clause)
            if det_colors:
                color_clause = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], det_colors[:2])
                if color_clause:
                    q = q.or_(color_clause)
            if or_clause:
                q = q.or_(or_clause)
            
            resp = q.limit(8).execute()
            rows = resp.data or []
            
            # FALLBACK LEVEL 1: Single tokens
            if not rows and keywords:
                search_fallback_level = 1
                print(f"üîÑ [FALLBACK 1] Trying with single tokens")
                single_tokens = [t for t in keywords if len(t.split()) == 1 and len(t) > 2]
                if single_tokens:
                    or_clause_2 = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], single_tokens)
                    q2 = supabase.table("products").select(
                        "ma_san_pham,ten_san_pham,mo_ta_san_pham,gia_ban,muc_gia_goc,product_images(duong_dan_anh)"
                    )
                    if min_price is not None:
                        q2 = q2.gte("gia_ban", min_price)
                    if max_price is not None:
                        q2 = q2.lte("gia_ban", max_price)
                    if or_clause_2:
                        q2 = q2.or_(or_clause_2)
                    resp2 = q2.limit(8).execute()
                    rows = resp2.data or []
            
            # FALLBACK LEVEL 2: Remove price constraints
            if not rows and (min_price is not None or max_price is not None):
                search_fallback_level = 2
                print(f"üîÑ [FALLBACK 2] Removing price constraints")
                q3 = supabase.table("products").select(
                    "ma_san_pham,ten_san_pham,mo_ta_san_pham,gia_ban,muc_gia_goc,product_images(duong_dan_anh)"
                )
                if or_clause:
                    q3 = q3.or_(or_clause)
                if det_type:
                    type_clause = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], [det_type])
                    if type_clause:
                        q3 = q3.or_(type_clause)
                resp3 = q3.limit(8).execute()
                rows = resp3.data or []
            
            # FALLBACK LEVEL 3: Products by type only
            if not rows and det_type:
                search_fallback_level = 3
                print(f"üîÑ [FALLBACK 3] Getting products by type: {det_type}")
                type_clause = build_or_clause_for_keywords(["ten_san_pham", "mo_ta_san_pham"], [det_type])
                if type_clause:
                    q4 = supabase.table("products").select(
                        "ma_san_pham,ten_san_pham,mo_ta_san_pham,gia_ban,muc_gia_goc,product_images(duong_dan_anh)"
                    ).or_(type_clause).limit(8)
                    resp4 = q4.execute()
                    rows = resp4.data or []
            
            # FALLBACK LEVEL 4: ANY products (last resort)
            if not rows:
                search_fallback_level = 4
                print(f"üîÑ [FALLBACK 4] Getting random popular products")
                q5 = supabase.table("products").select(
                    "ma_san_pham,ten_san_pham,mo_ta_san_pham,gia_ban,muc_gia_goc,product_images(duong_dan_anh)"
                ).limit(8)
                resp5 = q5.execute()
                rows = resp5.data or []
            
            # Sort by relevance
            def rank_row(r: Dict[str, Any]) -> tuple:
                name = (r.get("ten_san_pham") or "").lower()
                desc = (r.get("mo_ta_san_pham") or "").lower()
                txt = name + " " + desc
                score = score_product(r, keywords)
                type_bonus = 3 if det_type and det_type in txt else 0
                color_bonus = sum(1 for c in det_colors if c in txt) if det_colors else 0
                price_penalty = 0
                price = float(r.get("gia_ban") or 0)
                if min_price is not None or max_price is not None:
                    center = ((min_price or price) + (max_price or price)) / 2.0
                    price_penalty = abs(price - center) / max(center, 1.0)
                return (score + type_bonus + color_bonus, -price_penalty)

            rows_sorted = sorted(rows, key=lambda r: rank_row(r), reverse=True)
            suggested_products = [map_product_row(r) for r in rows_sorted[:6]]
            
            print(f"üîç [SEARCH] Found {len(suggested_products)} products (fallback level: {search_fallback_level})")
        
        # Format the chat prompt with context
        formatted_prompt = CHAT_PROMPT.format(
            customer_name=customer_name,
            height=height,
            weight=weight,
            favorite_colors=favorite_colors_str,
            chat_history=chat_history_str,
            current_intent=user_intent,
            products_found=len(suggested_products),
            user_message=user_message
        )
        
        # ADD PRODUCT DETAILS TO PROMPT (so AI knows exact prices)
        if suggested_products:
            formatted_prompt += "\n\nüì¶ **S·∫¢N PH·∫®M T√åM ƒê∆Ø·ª¢C** (PH·∫¢I d√πng th√¥ng tin n√†y, KH√îNG ƒë∆∞·ª£c b·ªãa):\n"
            for i, prod in enumerate(suggested_products[:6], 1):
                price = prod.get('price', 0)
                name = prod.get('name', 'Kh√¥ng r√µ t√™n')
                formatted_prompt += f"{i}. {name} - Gi√°: {int(price):,}ƒë\n"
            formatted_prompt += "\n‚ö†Ô∏è QUAN TR·ªåNG: Khi ƒë·ªÅ c·∫≠p gi√°, PH·∫¢I d√πng CH√çNH X√ÅC gi√° tr√™n, KH√îNG ƒë∆∞·ª£c l√†m tr√≤n ho·∫∑c b·ªãa s·ªë kh√°c!\n"
        
        # ADD FALLBACK INFO TO PROMPT
        if search_fallback_level > 0:
            fallback_notes = {
                1: "S·∫£n ph·∫©m t√¨m ƒë∆∞·ª£c b·∫±ng c√°ch m·ªü r·ªông t·ª´ kh√≥a",
                2: "S·∫£n ph·∫©m t√¨m ƒë∆∞·ª£c sau khi b·ªè gi·ªõi h·∫°n gi√°",
                3: "S·∫£n ph·∫©m t√¨m ƒë∆∞·ª£c theo lo·∫°i t∆∞∆°ng t·ª±",
                4: "S·∫£n ph·∫©m g·ª£i √Ω ph·ªï bi·∫øn cho b·∫°n"
            }
            formatted_prompt += f"\n\n‚ö†Ô∏è L∆ØU √ù: {fallback_notes[search_fallback_level]}. H√£y GI·∫¢I TH√çCH r√µ r√†ng cho kh√°ch h√†ng t·∫°i sao kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ch√≠nh x√°c, v√† ƒê·ªÄ XU·∫§T c√°c s·∫£n ph·∫©m thay th·∫ø m·ªôt c√°ch T·ª∞ NHI√äN, T√çCH C·ª∞C."
        
        # Prepare content for Gemini
        if file_path:
            uploaded_file = genai.upload_file(file_path, mime_type=mime_type)
            parts = [uploaded_file, formatted_prompt]
        else:
            parts = [formatted_prompt]
        
        # Generate AI response
        response = model.generate_content(parts)
        ai_message = (response.text or "").strip()
        
        # Ensure natural response
        if not ai_message:
            if user_intent == "greeting":
                ai_message = f"Ch√†o {customer_name}! M√¨nh l√† Mina ƒë√¢y üòä H√¥m nay m√¨nh c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"
            elif user_intent == "product_search" and suggested_products:
                ai_message = f"M√¨nh t√¨m ƒë∆∞·ª£c {len(suggested_products)} s·∫£n ph·∫©m ph√π h·ª£p cho b·∫°n! Xem th·ª≠ nh√© üòç"
            elif user_intent == "product_search" and not suggested_products:
                ai_message = "√öi, m√¨nh ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p. B·∫°n c√≥ th·ªÉ m√¥ t·∫£ r√µ h∆°n ƒë∆∞·ª£c kh√¥ng?"
            else:
                ai_message = "M√¨nh ƒëang s·∫µn s√†ng t∆∞ v·∫•n cho b·∫°n! B·∫°n mu·ªën h·ªèi g√¨ n√†o? üòä"
        
        return {
            "ai_message": ai_message,
            "suggested_products": suggested_products,
            "keywords": keywords,
            "user_intent": user_intent,
            "notes": extracted.get("conversation_context", "")
        }
        
    except Exception as e:
        print(f"[generate_ai_response] error: {e}")
        import traceback
        traceback.print_exc()
        return {
            "ai_message": "√îi, m√¨nh g·∫∑p ch√∫t v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. B·∫°n th·ª≠ l·∫°i sau nh√©! üòÖ",
            "suggested_products": [],
            "keywords": [],
            "user_intent": "error",
            "notes": "L·ªói h·ªá th·ªëng"
        }


@app.route("/api/chat", methods=["POST"])
def chat():
    try:
        data = request.get_json(silent=True) or {}
        user_message = data.get("message", "").strip()
        chat_history = data.get("chat_history", [])
        user_profile = data.get("user_profile", {})
        
        if not user_message:
            return jsonify({"error": "Tin nh·∫Øn kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"}), 400
        
        print(f"üí¨ [Chat] User: {user_message}")
        print(f"üí¨ [Chat] History: {len(chat_history)} messages")
        
        # Generate AI response
        result = generate_ai_response(
            user_message, chat_history, user_profile, None, None
        )
        
        return jsonify(result)
        
    except Exception as e:
        print(f"‚ùå Error /api/chat: {e}")
        return jsonify({"error": f"L·ªói m√°y ch·ªß: {str(e)}"}), 500


@app.route("/api/chat_with_image", methods=["POST"])
def chat_with_image():
    try:
        user_message = request.form.get("message", "").strip()
        chat_history_str = request.form.get("chat_history", "[]")
        user_profile_str = request.form.get("user_profile", "{}")
        file_path = None
        mime_type = None
        
        # Parse JSON strings
        try:
            chat_history = json.loads(chat_history_str) if chat_history_str else []
            user_profile = json.loads(user_profile_str) if user_profile_str else {}
        except json.JSONDecodeError:
            chat_history = []
            user_profile = {}
        
        if not user_message:
            return jsonify({"error": "Tin nh·∫Øn kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"}), 400
        
        # Handle image upload
        file = request.files.get("image")
        if file and file.filename:
            if not is_allowed_image(file.filename):
                return jsonify({"error": "Ch·ªâ ch·∫•p nh·∫≠n ·∫£nh .jpg, .jpeg, .png, .webp"}), 400
            
            file.seek(0, os.SEEK_END)
            size = file.tell()
            file.seek(0)
            if size > MAX_FILE_SIZE:
                return jsonify({"error": "File qu√° l·ªõn (t·ªëi ƒëa 20MB)"}), 400
            
            filename = secure_filename(file.filename)
            mime_type = get_mime_type(filename)
            suffix = "." + filename.rsplit(".", 1)[1].lower()
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                file.save(tmp.name)
                file_path = tmp.name
        
        print(f"üì∏ [Chat Image] User: {user_message}, Has image: {file_path is not None}")
        
        # Generate AI response with image
        result = generate_ai_response(user_message, chat_history, user_profile, file_path, mime_type)
        
        # Clean up temp file
        if file_path and os.path.exists(file_path):
            try:
                os.unlink(file_path)
            except Exception:
                pass
        
        return jsonify(result)
        
    except Exception as e:
        print(f"‚ùå Error /api/chat_with_image: {e}")
        return jsonify({"error": f"L·ªói m√°y ch·ªß: {str(e)}"}), 500


# -----------------------------
# Size recommendation helpers
# -----------------------------

def _parse_number(s: Any) -> float | None:
    try:
        if s is None:
            return None
        if isinstance(s, (int, float)):
            return float(s)
        s = str(s).strip().lower()
        if not s:
            return None
        s = s.replace('cm', '').replace('kg', '').replace('m', ' ').replace(',', '.')
        s = ''.join(ch for ch in s if ch.isdigit() or ch == '.' or ch == ' ')
        s = s.strip()
        if not s:
            return None
        return float(s)
    except Exception:
        return None


def parse_height_cm(height: Any) -> float | None:
    h = _parse_number(height)
    if h is None:
        return None
    if 1.3 <= h <= 2.3:
        return h * 100.0
    if 130 <= h <= 230:
        return float(h)
    return None


def parse_weight_kg(weight: Any) -> float | None:
    w = _parse_number(weight)
    if w is None:
        return None
    if 30 <= w <= 200:
        return float(w)
    return None


def recommend_size(
    *,
    height_cm: float | None,
    weight_kg: float | None,
    bust_cm: float | None = None,
    waist_cm: float | None = None,
    hip_cm: float | None = None,
    category: str | None = None,
    gender: str | None = None,
) -> dict:
    """Heuristic size recommendation"""
    size = 'M'
    reasons: list[str] = []

    top_chart = [
        {'size': 'S', 'bust_max': 84, 'waist_max': 66},
        {'size': 'M', 'bust_max': 88, 'waist_max': 70},
        {'size': 'L', 'bust_max': 92, 'waist_max': 74},
        {'size': 'XL', 'bust_max': 96, 'waist_max': 78},
        {'size': 'XXL', 'bust_max': 100, 'waist_max': 82},
    ]
    bottom_chart = [
        {'size': 'S', 'waist_max': 66, 'hip_max': 90},
        {'size': 'M', 'waist_max': 70, 'hip_max': 94},
        {'size': 'L', 'waist_max': 74, 'hip_max': 98},
        {'size': 'XL', 'waist_max': 78, 'hip_max': 102},
        {'size': 'XXL', 'waist_max': 82, 'hip_max': 106},
    ]

    if height_cm and weight_kg:
        h_m = height_cm / 100.0
        bmi = weight_kg / (h_m * h_m)
        reasons.append(f"BMI‚âà{bmi:.1f}")
        if bmi < 18.5:
            size = 'S'
        elif bmi < 23:
            size = 'M'
        elif bmi < 27.5:
            size = 'L'
        elif bmi < 30:
            size = 'XL'
        else:
            size = 'XXL'  # Th√™m size XXL cho BMI > 30

    cat = (category or '').lower()
    if cat in ('top', 'dress') and (bust_cm or waist_cm):
        for row in top_chart:
            ok_bust = (bust_cm is None) or (bust_cm <= row['bust_max'])
            ok_waist = (waist_cm is None) or (waist_cm <= row['waist_max'])
            if ok_bust and ok_waist:
                size = row['size']
                reasons.append(f"ng·ª±c‚â§{row['bust_max']}cm, eo‚â§{row['waist_max']}cm")
                break
    if cat in ('bottom',) and (waist_cm or hip_cm):
        for row in bottom_chart:
            ok_waist = (waist_cm is None) or (waist_cm <= row['waist_max'])
            ok_hip = (hip_cm is None) or (hip_cm <= row['hip_max'])
            if ok_waist and ok_hip:
                size = row['size']
                reasons.append(f"eo‚â§{row['waist_max']}cm, m√¥ng‚â§{row['hip_max']}cm")
                break

    if height_cm:
        if height_cm < 155 and size in ('M', 'L', 'XL', 'XXL'):
            reasons.append('th·∫•p, gi·∫£m 1 size')
            size_map = {'M': 'S', 'L': 'M', 'XL': 'L', 'XXL': 'XL'}
            size = size_map.get(size, size)
        if height_cm > 170 and size in ('S', 'M'):
            reasons.append('cao, tƒÉng 1 size')
            size_map = {'S': 'M', 'M': 'L'}
            size = size_map.get(size, size)

    return {
        'size': size,
        'notes': ', '.join(reasons) if reasons else 'D·ª±a tr√™n s·ªë ƒëo cung c·∫•p',
        'inputs': {
            'height_cm': height_cm,
            'weight_kg': weight_kg,
            'bust_cm': bust_cm,
            'waist_cm': waist_cm,
            'hip_cm': hip_cm,
            'category': category,
            'gender': gender,
        }
    }


@app.route("/api/recommend_size", methods=["POST"])
def recommend_size_api():
    try:
        data = request.get_json(silent=True) or {}
        height_raw = data.get('height')
        weight_raw = data.get('weight')
        bust = _parse_number(data.get('bust'))
        waist = _parse_number(data.get('waist'))
        hip = _parse_number(data.get('hip'))
        category = data.get('category')
        gender = data.get('gender')
        use_gemini = bool(data.get('use_gemini'))

        height = parse_height_cm(height_raw)
        weight = parse_weight_kg(weight_raw)

        # Lu√¥n s·ª≠ d·ª•ng Gemini ƒë·ªÉ g·ª£i √Ω size
        try:
            prompt = (
                "B·∫°n l√† stylist chuy√™n nghi·ªáp. H√£y g·ª£i √Ω size cho ph·ª• n·ªØ (S/M/L/XL/XXL) d·ª±a tr√™n s·ªë ƒëo sau:\n"
                f"Chi·ªÅu cao: {height_raw}, C√¢n n·∫∑ng: {weight_raw}, Ng·ª±c: {bust}cm, Eo: {waist}cm, M√¥ng: {hip}cm\n"
                f"Danh m·ª•c: {category or 'kh√¥ng r√µ'}, Gi·ªõi t√≠nh: {gender or 'kh√¥ng r√µ'}\n\n"
                "H∆Ø·ªöNG D·∫™N G·ª¢I √ù SIZE:\n"
                "1. T√≠nh BMI = c√¢n n·∫∑ng(kg) / (chi·ªÅu cao(m))¬≤\n"
                "2. Xem x√©t s·ªë ƒëo c·ª• th·ªÉ (ng·ª±c, eo, m√¥ng)\n"
                "3. ƒêi·ªÅu ch·ªânh theo chi·ªÅu cao:\n"
                "   - Ng∆∞·ªùi th·∫•p (<155cm): c√≥ th·ªÉ gi·∫£m 1 size\n"
                "   - Ng∆∞·ªùi cao (>170cm): c√≥ th·ªÉ tƒÉng 1 size\n"
                "4. Xem x√©t danh m·ª•c s·∫£n ph·∫©m (top/dress/bottom)\n\n"
                "QUY T·∫ÆC SIZE THAM KH·∫¢O:\n"
                "- S: BMI < 18.5, s·ªë ƒëo nh·ªè, ng·ª±c ‚â§84cm, eo ‚â§66cm\n"
                "- M: BMI 18.5-23, c√¢n ƒë·ªëi, ng·ª±c ‚â§88cm, eo ‚â§70cm\n"
                "- L: BMI 23-27.5, h∆°i ƒë·∫ßy ƒë·∫∑n, ng·ª±c ‚â§92cm, eo ‚â§74cm\n"
                "- XL: BMI 27.5-30, ƒë·∫ßy ƒë·∫∑n, ng·ª±c ‚â§96cm, eo ‚â§78cm\n"
                "- XXL: BMI > 30, r·∫•t ƒë·∫ßy ƒë·∫∑n, ng·ª±c ‚â§100cm, eo ‚â§82cm\n\n"
                "Tr·∫£ v·ªÅ JSON duy nh·∫•t: {\"size\":\"S|M|L|XL|XXL\", \"notes\":\"l√Ω do chi ti·∫øt\", \"bmi\":\"BMI t√≠nh ƒë∆∞·ª£c\"}"
            )
            
            resp = model.generate_content([prompt])
            text = (resp.text or '').strip()
            
            # X·ª≠ l√Ω response t·ª´ Gemini
            if text.startswith("```"):
                lines = text.split("\n")
                text = "\n".join(lines[1:-1]) if len(lines) > 2 else text
            text = text.strip()
            
            try:
                rec = json.loads(text)
                if isinstance(rec, dict) and rec.get('size'):
                    size = str(rec.get('size')).upper()
                    if size not in ('S','M','L','XL','XXL'):
                        size = 'M'
                    return jsonify({
                        'size': size,
                        'notes': rec.get('notes') or 'Theo Gemini AI',
                        'bmi': rec.get('bmi', ''),
                        'source': 'gemini'
                    })
            except json.JSONDecodeError:
                # Fallback: t√¨m size trong text
                size_match = re.search(r'\b(S|M|L|XL|XXL)\b', text, re.IGNORECASE)
                if size_match:
                    size = size_match.group(1).upper()
                    return jsonify({
                        'size': size,
                        'notes': f'Gemini g·ª£i √Ω: {text[:100]}...',
                        'source': 'gemini'
                    })
            
        except Exception as e:
            print(f"[recommend_size_api] gemini error: {e}")
            # Fallback v·ªÅ heuristic n·∫øu Gemini l·ªói
            result = recommend_size(
                height_cm=height,
                weight_kg=weight,
                bust_cm=bust,
                waist_cm=waist,
                hip_cm=hip,
                category=category,
                gender=gender,
            )
            result['source'] = 'heuristic_fallback'
            return jsonify(result)
    except Exception as e:
        print(f"‚ùå Error /api/recommend_size: {e}")
        return jsonify({'error': f'L·ªói m√°y ch·ªß: {str(e)}'}), 500


@app.route("/api/health", methods=["GET"])
def health():
    return jsonify({"ok": True})

if __name__ == "__main__":
    # set GEMINI_API_KEY=... && set SUPABASE_URL=... && set SUPABASE_ANON_KEY=... && python app_gemini_product_search.py
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port, debug=False)













